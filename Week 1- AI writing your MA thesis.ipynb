{"cells":[{"cell_type":"markdown","metadata":{"id":"7UqCHPivfTSD"},"source":["Based on: https://www.tensorflow.org/text/tutorials/text_generation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RtG8Pk8lFpAN"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"WtOvGAC_fbC6"},"source":["Import libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3497,"status":"ok","timestamp":1648914111236,"user":{"displayName":"WillArt","userId":"11279162893725792630"},"user_tz":-120},"id":"wAVDzgJdfXGX"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.layers.experimental import preprocessing\n","\n","import numpy as np\n","import os\n","import time"]},{"cell_type":"markdown","metadata":{"id":"taWfNJirfiu2"},"source":["Read previous year's MA theses"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":505,"status":"ok","timestamp":1648914115776,"user":{"displayName":"WillArt","userId":"11279162893725792630"},"user_tz":-120},"id":"c9YFm8a2frdh","outputId":"4145d178-d8c7-4398-b274-4ca113920e80"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://raw.githubusercontent.com/Joaoffg/DSS_algorithms/main/theses.txt\n","2342912/2334957 [==============================] - 0s 0us/step\n","2351104/2334957 [==============================] - 0s 0us/step\n","Length of text: 2333994 characters\n"]}],"source":["url = tf.keras.utils.get_file('theses.txt', 'https://raw.githubusercontent.com/Joaoffg/DSS_algorithms/main/theses.txt')\n","\n","# Read, then decode for py2 compat.\n","text = open(url, 'rb').read().decode(encoding='utf-8')\n","# length of text is the number of characters in it\n","print(f'Length of text: {len(text)} characters')"]},{"cell_type":"markdown","metadata":{"id":"d9N6k_5JkQ_O"},"source":["Convert all of the characters in the theses to numbers that are readable by an neural network (e.g. 1 = 'a'; 2 = 'b')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9515,"status":"ok","timestamp":1648914135212,"user":{"displayName":"WillArt","userId":"11279162893725792630"},"user_tz":-120},"id":"dLmXdCRjkaCh","outputId":"5df3e95a-ea21-4e59-eb1e-a5de19a858ea"},"outputs":[{"name":"stdout","output_type":"stream","text":["146 unique characters\n","tf.Tensor(\n","[b'\\xef\\xbb\\xbf' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b'\\r'\n"," b'\\n' b'\\r' b'\\n' b' ' b'\\r' b'\\n' b'A' b'l' b'g' b'o' b'r' b'i' b't'\n"," b'h' b'm' b's' b' ' b't' b'o' b'l' b'd' b' ' b'm' b'e' b' ' b't' b'o'\n"," b' ' b'b' b'u' b'y' b' ' b'i' b't' b'\\r' b'\\n' b' ' b' ' b' ' b'T' b'o'\n"," b' ' b'w' b'h' b'a' b't' b' ' b'e' b'x' b't' b'e' b'n' b't' b' ' b'd'\n"," b'o' b' ' b'A' b'm' b'a' b'z' b'o' b'n' b\"'\" b's' b' ' b'r' b'e' b'c'\n"," b'o' b'm' b'm' b'e' b'n' b'd' b'a' b't' b'i' b'o' b'n' b's' b' ' b'i'\n"," b'n' b'f' b'l' b'u' b'e' b'n'], shape=(101,), dtype=string)\n","b\"\\xef\\xbb\\xbf          \\r\\n\\r\\n \\r\\nAlgorithms told me to buy it\\r\\n   To what extent do Amazon's recommendations influen\"\n","b'ce the choice of its customers?\\r\\n \\r\\n \\r\\n \\r\\n \\r\\n\\r\\n\\r\\nStudent Name:        Mihael Gelo\\r\\n   Student Number:'\n","b'    512149\\r\\n \\r\\n   Supervisor:   \\t\\tJo\\xc3\\xa3o Gon\\xc3\\xa7alves, MSc.\\r\\n \\r\\n   \\r\\n   Master Media Studies. Media \u0026 Crea'\n","b'tive Industries\\r\\nErasmus School of History, Culture and Communication \\r\\n   Erasmus University Rotterd'\n","b'am, The Netherlands\\r\\n \\r\\n \\r\\n\\r\\n   Master Thesis  \\r\\n   June 27th, 2019\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nTable of'\n"]}],"source":["# The unique characters in the file\n","vocab = sorted(set(text))\n","print(f'{len(vocab)} unique characters')\n","\n","ids_from_chars = preprocessing.StringLookup(\n","    vocabulary=list(vocab), mask_token=None)\n","\n","chars_from_ids = tf.keras.layers.experimental.preprocessing.StringLookup(\n","    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n","\n","def text_from_ids(ids):\n","  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)\n","\n","all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n","all_ids\n","\n","ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n","\n","seq_length = 100\n","examples_per_epoch = len(text)//(seq_length+1)\n","\n","sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n","\n","for seq in sequences.take(1):\n","  print(chars_from_ids(seq))\n","\n","for seq in sequences.take(5):\n","  print(text_from_ids(seq).numpy())\n","\n","def split_input_target(sequence):\n","    input_text = sequence[:-1]\n","    target_text = sequence[1:]\n","    return input_text, target_text\n","\n","dataset = sequences.map(split_input_target)"]},{"cell_type":"markdown","metadata":{"id":"z4OZyeXhdG6i"},"source":["Create the Neural Network"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9623,"status":"ok","timestamp":1648914151396,"user":{"displayName":"WillArt","userId":"11279162893725792630"},"user_tz":-120},"id":"z1dfJn1PmRdx","outputId":"73704301-79a4-4cf7-cc84-1d6cef40976c"},"outputs":[{"name":"stdout","output_type":"stream","text":["(64, 100, 147) # (batch_size, sequence_length, vocab_size)\n","Model: \"my_model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       multiple                  37632     \n","                                                                 \n"," gru (GRU)                   multiple                  3938304   \n","                                                                 \n"," dense (Dense)               multiple                  150675    \n","                                                                 \n","=================================================================\n","Total params: 4,126,611\n","Trainable params: 4,126,611\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["# Batch size\n","BATCH_SIZE = 64\n","\n","# Buffer size to shuffle the dataset\n","# (TF data is designed to work with possibly infinite sequences,\n","# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n","# it maintains a buffer in which it shuffles elements).\n","BUFFER_SIZE = 10000\n","\n","dataset = (\n","    dataset\n","    .shuffle(BUFFER_SIZE)\n","    .batch(BATCH_SIZE, drop_remainder=True)\n","    .prefetch(tf.data.experimental.AUTOTUNE))\n","\n","dataset\n","\n","# Length of the vocabulary in chars\n","vocab_size = len(vocab)\n","\n","# The embedding dimension\n","embedding_dim = 256\n","\n","# Number of RNN units\n","rnn_units = 1024\n","\n","class MyModel(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_dim, rnn_units):\n","    super().__init__(self)\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","    self.gru = tf.keras.layers.GRU(rnn_units,\n","                                   return_sequences=True,\n","                                   return_state=True)\n","    self.dense = tf.keras.layers.Dense(vocab_size)\n","\n","  def call(self, inputs, states=None, return_state=False, training=False):\n","    x = inputs\n","    x = self.embedding(x, training=training)\n","    if states is None:\n","      states = self.gru.get_initial_state(x)\n","    x, states = self.gru(x, initial_state=states, training=training)\n","    x = self.dense(x, training=training)\n","\n","    if return_state:\n","      return x, states\n","    else:\n","      return x\n","\n","model = MyModel(\n","    # Be sure the vocabulary size matches the `StringLookup` layers.\n","    vocab_size=len(ids_from_chars.get_vocabulary()),\n","    embedding_dim=embedding_dim,\n","    rnn_units=rnn_units)\n","\n","for input_example_batch, target_example_batch in dataset.take(1):\n","    example_batch_predictions = model(input_example_batch)\n","    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n","\n","\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"JllVpUqMzA2W"},"source":["Train the model (you can increse the number of EPOCHS to make a better model, but it will also take longer)."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"Z7vBEXojm89j"},"outputs":[{"name":"stdout","output_type":"stream","text":["Prediction shape:  (64, 100, 147)  # (batch_size, sequence_length, vocab_size)\n","Mean loss:         4.990237\n","Epoch 1/5\n","361/361 [==============================] - 72s 188ms/step - loss: 2.3934\n","Epoch 2/5\n","361/361 [==============================] - 70s 189ms/step - loss: 1.3975\n","Epoch 3/5\n","361/361 [==============================] - 70s 188ms/step - loss: 1.1610\n","Epoch 4/5\n","361/361 [==============================] - 69s 188ms/step - loss: 1.0597\n","Epoch 5/5\n","361/361 [==============================] - 69s 187ms/step - loss: 0.9912\n"]}],"source":["loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n","\n","example_batch_loss = loss(target_example_batch, example_batch_predictions)\n","mean_loss = example_batch_loss.numpy().mean()\n","print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n","print(\"Mean loss:        \", mean_loss)\n","\n","tf.exp(mean_loss).numpy()\n","\n","model.compile(optimizer='adam', loss=loss)\n","\n","# Directory where the checkpoints will be saved\n","checkpoint_dir = './training_checkpoints'\n","# Name of the checkpoint files\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n","\n","checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_prefix,\n","    save_weights_only=True)\n","\n","EPOCHS = 5\n","\n","history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"]},{"cell_type":"markdown","metadata":{"id":"F91Qos5LzOYt"},"source":["Generate text (you can specify the input to be completed by changing the sentence in prediction_input, just make sure to keep it between ' ')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2963,"status":"ok","timestamp":1644337912790,"user":{"displayName":"João Gonçalves","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18028545460101754877"},"user_tz":-60},"id":"3sFCu6s-oSnV","outputId":"a2b385ae-3753-415d-c27a-c1bc26f3f309"},"outputs":[{"name":"stdout","output_type":"stream","text":["The input is: The research question is \n","The research question is low levels of credibility\r\n","\r\n","\r\n","91.1.2 Sampling\r\n","\tIt was expected to be satisfied with this study. This is a result, the difference between people who are highly complexely than 34% of the two Trump 2021 campaigns, mainly filled in the case of H2b, Hayes (2017) argues that some celebrity end it in group (2) belong to a study, the findings of this study is that the black - o.7, however, recommendations can provide more male models for audience. It internated decision model 4, the global individual \n","\n","________________________________________________________________________________\n","\n","Run time: 2.776083469390869\n"]}],"source":["prediction_input = 'The research question is '\n","\n","class OneStep(tf.keras.Model):\n","  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n","    super().__init__()\n","    self.temperature = temperature\n","    self.model = model\n","    self.chars_from_ids = chars_from_ids\n","    self.ids_from_chars = ids_from_chars\n","\n","    # Create a mask to prevent \"[UNK]\" from being generated.\n","    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n","    sparse_mask = tf.SparseTensor(\n","        # Put a -inf at each bad index.\n","        values=[-float('inf')]*len(skip_ids),\n","        indices=skip_ids,\n","        # Match the shape to the vocabulary\n","        dense_shape=[len(ids_from_chars.get_vocabulary())])\n","    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n","\n","  @tf.function\n","  def generate_one_step(self, inputs, states=None):\n","    # Convert strings to token IDs.\n","    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n","    input_ids = self.ids_from_chars(input_chars).to_tensor()\n","\n","    # Run the model.\n","    # predicted_logits.shape is [batch, char, next_char_logits]\n","    predicted_logits, states = self.model(inputs=input_ids, states=states,\n","                                          return_state=True)\n","    # Only use the last prediction.\n","    predicted_logits = predicted_logits[:, -1, :]\n","    predicted_logits = predicted_logits/self.temperature\n","    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n","    predicted_logits = predicted_logits + self.prediction_mask\n","\n","    # Sample the output logits to generate token IDs.\n","    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n","    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n","\n","    # Convert from token ids to characters\n","    predicted_chars = self.chars_from_ids(predicted_ids)\n","\n","    # Return the characters and model state.\n","    return predicted_chars, states\n","\n","one_step_model = OneStep(model, chars_from_ids, ids_from_chars)\n","\n","start = time.time()\n","states = None\n","next_char = tf.constant([prediction_input])\n","result = [next_char]\n","\n","for n in range(500):\n","  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n","  result.append(next_char)\n","\n","result = tf.strings.join(result)\n","end = time.time()\n","print(\"The input is: \" + prediction_input)\n","print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n","print('\\nRun time:', end - start)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Week 1- AI writing your MA thesis.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}