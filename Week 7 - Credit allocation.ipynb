{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Week 7 - Credit allocation.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":[""],"metadata":{"id":"trmA0tDm4a8G"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Using Machine Learning to decide on credit allocation\n","\n","This week we are using a logistic regression to decide which customers in Germany should be entitled to credit or not. We are using a donated dataset from 1994 for this, you can find more information about the dataset and its variables here: https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)"],"metadata":{"id":"TGBTDCjxyrKb"}},{"cell_type":"markdown","source":["## Importing the libraries and loading the dataset\n","\n","Because we are not using neural networks or any form of \"deep\" learning this week, we no longer need to import keras. Instead, we are using Scikit-learn, which covers most traditional machine learning algorithms. We also use Pandas again for database management."],"metadata":{"id":"OSaIaogFzS3j"}},{"cell_type":"code","source":["from pandas import read_csv\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.compose import ColumnTransformer\n","from sklearn.linear_model import LogisticRegression\n","from imblearn.pipeline import Pipeline\n","from imblearn.under_sampling import RepeatedEditedNearestNeighbours\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import RepeatedStratifiedKFold\n","from sklearn.metrics import fbeta_score\n","from sklearn.metrics import make_scorer\n","from sklearn.linear_model import RidgeClassifier\n","from numpy import mean\n","from numpy import std\n","from imblearn.pipeline import Pipeline\n","from imblearn.combine import SMOTEENN\n","from imblearn.under_sampling import EditedNearestNeighbours"],"metadata":{"id":"v8YV_QMMz88s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["As usual, we upload our training data."],"metadata":{"id":"INkKOj0F35xY"}},{"cell_type":"code","source":["# Upload your dataset here by clicking \"Choose Files\" after running the code. \n","# It should be in .csv format and  named \"german.csv\"\n","\n","from google.colab import files\n","\n","uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n","  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","      name=fn, length=len(uploaded[fn])))"],"metadata":{"id":"ndq7Wyk30aor"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This step loads the dataset. Like in previous cases, the algorithm can only read numbers, so all of the categorical variables in the dataset need to be converted into numbers."],"metadata":{"id":"iZe5aNVG4AkU"}},{"cell_type":"code","source":["def load_dataset(full_path):\n","\t# load the dataset as a numpy array\n","\tdataframe = read_csv(full_path, header=None)\n","\tlast_ix = len(dataframe.columns) - 1\n","\tX, y = dataframe.drop(last_ix, axis=1), dataframe[last_ix]\n","\t# select categorical and numerical features\n","\tcat_ix = X.select_dtypes(include=['object', 'bool']).columns\n","\tnum_ix = X.select_dtypes(include=['int64', 'float64']).columns\n","\t# label encode the target variable to have the classes 0 and 1\n","\ty = LabelEncoder().fit_transform(y)\n","\treturn X.values, y, cat_ix, num_ix\n","\n","# define the location of the dataset\n","full_path = 'german.csv'\n","# load the dataset\n","X, y, cat_ix, num_ix = load_dataset(full_path)"],"metadata":{"id":"F0ERlV6v0WHU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Defining and training the model\n","As usual, this is the step where we train the logistic regression model. However, unlike neural networks, validation performance is less relevant for logistic regressions."],"metadata":{"id":"CBy-JvaK40-9"}},{"cell_type":"code","source":["# define model to evaluate\n","model = LogisticRegression(solver='liblinear', class_weight='balanced')\n","# one hot encode categorical, normalize numerical\n","ct = ColumnTransformer([('c',OneHotEncoder(),cat_ix), ('n',MinMaxScaler(),num_ix)])\n","# scale, then undersample, then fit model\n","pipeline = Pipeline(steps=[('t',ct), ('s', RepeatedEditedNearestNeighbours()), ('m',model)])\n","# fit the model\n","pipeline.fit(X, y)"],"metadata":{"id":"3YEieuLj445m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Evaluating the model\n","\n","Because there is not validation component in model training, we have to assess the performance of it after the training. First, we can calculate an F2 score (which is focused at reducing false negatives) to see how well the model is performing."],"metadata":{"id":"wu0zVfKpAbKX"}},{"cell_type":"code","source":["# calculate f2-measure\n","def f2_measure(y_true, y_pred):\n","\treturn fbeta_score(y_true, y_pred, beta=2)\n","\n","# evaluate a model\n","def evaluate_model(X, y, model):\n","\t# define evaluation procedure\n","\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n","\t# define the model evaluation metric\n","\tmetric = make_scorer(f2_measure)\n","\t# evaluate model\n","\tscores = cross_val_score(model, X, y, scoring=metric, cv=cv, n_jobs=-1)\n","\treturn scores\n"," \n","scores = evaluate_model(X, y, pipeline)\n","print('%.3f (%.3f)' % (mean(scores), std(scores)))"],"metadata":{"id":"t7sGaVcnAfDo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Finally, we can create some \"fictional\" customers to see what the decision of the algorithm is. If it outputs a prediction of 0 it means that the customer will be granted the credit, while a prediction of 1 means that no credit is given to that customer. If you are unsure of what the numbers and letters mean, you can again check the dataset information here: https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)\n","\n","In the data part, each row corresponds to an individual, who in turn gets a prediction. You can change these data. For instance, if you want to change the situation of the first customer to \"unemployed/ unskilled - non-resident\" you can change this variable from 'A174' to 'A171'."],"metadata":{"id":"zXmeVbHBI8xG"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"VRGF6umHfVvn"},"outputs":[],"source":["# evaluate on some good customers cases (known class 0)\n","print('Good Customers:')\n","data = [['A11', 6, 'A34', 'A43', 1169, 'A65', 'A75', 4, 'A93', 'A101', 4, 'A121', 67, 'A143', 'A152', 2, 'A174', 1, 'A192', 'A201'],\n","\t['A14', 12, 'A34', 'A46', 2096, 'A61', 'A74', 2, 'A93', 'A101', 3, 'A121', 49, 'A143', 'A152', 1, 'A172', 2, 'A191', 'A201'],\n","\t['A14', 24, 'A34', 'A49', 12096, 'A61', 'A71', 4, 'A92', 'A101', 3, 'A124', 25, 'A143', 'A151', 3, 'A171', 0, 'A191', 'A202']]\n","for row in data:\n","\t# make prediction\n","\tyhat = pipeline.predict([row])\n","\t# get the label\n","\tlabel = yhat[0]\n","\t# summarize\n","\tprint('>Predicted=%d (expected 0)' % (label))\n","# evaluate on some bad customers (known class 1)\n","print('Bad Customers:')\n","data = [['A13', 18, 'A32', 'A43', 2100, 'A61', 'A73', 4, 'A93', 'A102', 2, 'A121', 37, 'A142', 'A152', 1, 'A173', 1, 'A191', 'A201'],\n","\t['A11', 24, 'A33', 'A40', 4870, 'A61', 'A73', 3, 'A93', 'A101', 4, 'A124', 53, 'A143', 'A153', 2, 'A173', 2, 'A191', 'A201'],\n","\t['A11', 24, 'A32', 'A43', 1282, 'A62', 'A73', 4, 'A92', 'A101', 2, 'A123', 32, 'A143', 'A152', 1, 'A172', 1, 'A191', 'A201']]\n","for row in data:\n","\t# make prediction\n","\tyhat = pipeline.predict([row])\n","\t# get the label\n","\tlabel = yhat[0]\n","\t# summarize\n","\tprint('>Predicted=%d (expected 1)' % (label))"]}]}